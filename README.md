# IBM SkillsBuild 4-Week Internship on AI & Cloud Technologies
This repository documents the capstone project completed during the IBM SkillsBuild 4-Weeks Internship on AI & Cloud Technologies. This program is a collaborative initiative by the Edunet Foundation, AICTE, and IBM SkillsBuild.

The internship's primary goal is to provide hands-on experience in emerging technologies, enhancing employability and confidence by solving real-world challenges using the IBM SkillsBuild and IBM Cloud platforms.

ğŸ“ ## Table of Contents
- [Intern Details](#-intern-details)
- [About the Internship](#-about-the-internship)
- [Project: Intelligent Classification of PMGSY Schemes](#-project-intelligent-classification-of-pmgsy-schemes)
- [Problem Statement](#problem-statement)
- [Solution Overview](#solution-overview)
- [Technology Stack](#-technology-stack)
- [Project Workflow](#-project-workflow)
- [Results](#-results)
- [Repository Contents](#-repository-contents)

ğŸ‘¨â€ğŸ’» ## Intern Details
- **Name:** Harish Sonwale
- **Institute:** GAYA COLLEGE OF ENGINEERING
- **Duration:** 4 Weeks (15th July 2025 to 7th August 2025)

ğŸ“– ## About the Internship
This 4-week program focused on providing practical skills in AI and Cloud Computing. The internship was structured with weekly virtual sessions, mentor guidance, and hands-on labs. The curriculum included:

- **Week 1:** Internship Orientation, IBM Cloud Registration, Artificial Intelligence.
- **Week 2:** Data Analytics concepts, Hands-On Labs, and Cloud EDA.
- **Week 3 & 4:** Building a Chat Bot, AI/ML experiments on the cloud, and a deep dive into AutoAI experiments on IBM Cloud.

Successful completion required active participation, completion of at least two courses on IBM SkillsBuild, and the submission of a final project presentation. This internship was offered with no stipend.

ğŸ’¡ ## Project: Intelligent Classification of PMGSY Schemes
### Problem Statement
The Pradhan Mantri Gram Sadak Yojana (PMGSY) is a major rural development program with various schemes like PMGSY-I, PMGSY-II, etc. Manually classifying thousands of projects under these schemes is slow, error-prone, and unscalable. This inefficiency hinders effective monitoring, budget allocation, and impact assessment.

### Solution Overview
An end-to-end machine learning solution was developed to automate the classification of PMGSY projects. The system uses a project's physical and financial data to predict which PMGSY scheme it belongs to. The final, trained model was deployed as a real-time web service on the IBM Cloud platform.

âš™ï¸ ## Technology Stack
- **Cloud Platform:** IBM Cloud
- **AI/ML Service:** IBM watsonx.ai Studio
- **Automated ML Tool:** IBM AutoAI
- **Core Language & Libraries:**
  - Python
  - scikit-learn
  - pandas
  - XGBoost
  - ibm-watsonx-ai

ğŸš€ ## Project Workflow
1.  **Data Ingestion:** The PMGSY dataset from the AI Kosh portal was uploaded to an IBM Cloud project.
2.  **Automated Model Building:** An AutoAI experiment was configured in watsonx.ai. This powerful tool automated the entire machine learning pipeline, including data preprocessing, feature engineering, model selection, and hyperparameter optimization.
3.  **Model Selection:** AutoAI trained and ranked multiple classification algorithms. The XGBoost Classifier was identified as the best-performing model based on accuracy.
4.  **Deployment:** The top-performing pipeline was saved as a model asset and deployed as an Online Web Service within a Deployment Space on IBM Watsonx.ai, which provides a REST API for real-time predictions.
5.  **Testing:** The deployed API endpoint was successfully tested with sample data to validate its real-time classification capabilities.

ğŸ“Š ## Results
The deployed model demonstrated high accuracy in classifying infrastructure projects, proving the effectiveness of using automated AI tools for rapid development and deployment. The project successfully met all requirements for the final evaluation and submission.

![Screenshot (543)](https://user-images.githubusercontent.com/your-username/your-repo/assets/your-image1.png)
![Screenshot (544)](https://user-images.githubusercontent.com/your-username/your-repo/assets/your-image2.png)
![Screenshot (547)](https://user-images.githubusercontent.com/your-username/your-repo/assets/your-image3.png)
![Screenshot (562)](https://user-images.githubusercontent.com/your-username/your-repo/assets/your-image4.png)
![Screenshot (563)](https://user-images.githubusercontent.com/your-username/your-repo/assets/your-image5.png)


ğŸ“ ## Repository Contents
- **Pradhan Mantri Gram Sadak Yojana SCHEME Detector.ipynb:** The Jupyter Notebook automatically generated by IBM AutoAI, detailing the best pipeline's architecture and code.
- **Aditya_Kumar_4_Week_AI_Cloud_Internship_Project.pdf:** The final project presentation pdf submitted for evaluation.
- **README.md:** This file.

An intelligent classification system for Pradhan Mantri Gram Sadak Yojana (PMGSY) schemes using machine learning. This project automates the classification of PMGSY projects into different schemes based on their physical and financial data.

## ğŸ“‹ Project Overview

PMGSY is a major rural development program with various schemes like PMGSY-I, PMGSY-II, etc. This project provides an automated solution to classify thousands of projects under these schemes, which is typically a slow and error-prone manual process.

## ğŸš€ Features

- Automated classification of PMGSY projects
- Web-based interface for easy interaction
- REST API for integration with other systems
- Model training and evaluation pipeline
- Data preprocessing and feature engineering
- Sample dataset and pre-trained model for quick start

## ğŸ› ï¸ Technology Stack

- **Backend**: Python 3.8+, Flask
- **Frontend**: HTML5, CSS3, JavaScript, Bootstrap 5
- **Machine Learning**: scikit-learn, XGBoost, pandas, NumPy
- **Data Processing**: pandas, NumPy, scikit-learn
- **Model Persistence**: joblib
- **Development Tools**: Jupyter Notebook, VS Code

## ğŸ“ Project Structure

```
PMGSY-SCHEME-Detector/
â”œâ”€â”€ data/                   # Dataset files and uploads
â”‚   â””â”€â”€ sample_data.csv     # Sample dataset
â”œâ”€â”€ models/                 # Trained models
â”œâ”€â”€ notebooks/              # Jupyter notebooks for analysis
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ static/             # Static files (CSS, JS, images)
â”‚   â”‚   â”œâ”€â”€ css/            # Stylesheets
â”‚   â”‚   â””â”€â”€ js/             # JavaScript files
â”‚   â”œâ”€â”€ templates/          # HTML templates
â”‚   â”œâ”€â”€ app.py              # Main application
â”‚   â””â”€â”€ train_model.py      # Model training script
â”œâ”€â”€ tests/                  # Test files
â”œâ”€â”€ .gitignore             # Git ignore file
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ run.py                 # Application launcher
â””â”€â”€ setup.bat              # Windows setup script
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip (Python package installer)
- Git (optional, for version control)

### Installation (Windows)

1. **Clone the repository** (or download as ZIP and extract):
   ```
   git clone https://github.com/Harish2004-sonwale/PMGSY--SCHEME--Detector.git
   cd PMGSY--SCHEME--Detector
   ```

2. **Run the setup script**:
   Double-click on `setup.bat` or run it from the command prompt:
   ```
   .\setup.bat
   ```

   This will:
   - Create a Python virtual environment
   - Activate the environment
   - Install all required dependencies

### Manual Installation (Alternative)

If the setup script doesn't work, follow these steps:

1. Create and activate a virtual environment:
   ```
   python -m venv venv
   .\venv\Scripts\activate
   ```

2. Install the requirements:
   ```
   pip install -r requirements.txt
   ```

## ğŸƒ Running the Application

1. **Start the application**:
   ```
   python run.py
   ```

2. **Access the web interface**:
   Open your web browser and go to:
   ```
   http://localhost:5000
   ```

3. **Using the application**:
   - Enter project details in the form
   - Click "Predict Scheme" to get the classification
   - For batch processing, use the "Batch Prediction" tab

## ğŸ¤– Model Training

### Using the Sample Model

The application comes with a pre-trained sample model. If you want to train your own model:

1. Prepare your dataset in CSV format and place it in the `data/` directory

2. Train a new model:
   ```
   python -m src.train_model --data data/your_dataset.csv --model-type xgb
   ```

   Available model types: `xgb` (XGBoost) or `rf` (Random Forest)

3. The trained model will be saved in the `models/` directory

### Training with Jupyter Notebook

1. Start Jupyter Notebook:
   ```
   jupyter notebook
   ```

2. Open `notebooks/pmgsy_scheme_classification.ipynb`

3. Follow the notebook instructions to explore the data and train models

## ğŸŒ API Endpoints

The application provides the following REST API endpoints:

- `POST /predict` - Classify a single project
  ```json
  {
    "projectName": "Sample Project",
    "financialData": 250.75,
    "physicalProgress": 85.5
  }
  ```

- `POST /batch_predict` - Upload a CSV file for batch prediction
  ```
  curl -X POST -F "file=@data/sample_data.csv" http://localhost:5000/batch_predict
  ```

## ğŸ“Š Sample Dataset

A sample dataset is provided in `data/sample_data.csv` with the following columns:

- `project_id`: Unique identifier for the project
- `project_name`: Name of the project
- `financial_data`: Financial allocation (in lakhs)
- `physical_progress`: Physical progress percentage
- `state`: State where the project is located
- `district`: District of the project
- `block`: Block name
- `habitation`: Habitation name
- `road_length`: Length of the road (in km)
- `scheme`: Target variable (PMGSY-I, PMGSY-II, PMGSY-III)

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Special thanks to IBM SkillsBuild for the learning resources

## ğŸ¤ Contributing

Contributions are welcome! IBM CLOUD 

